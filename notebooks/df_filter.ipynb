{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8b9506-0168-46c3-9fae-a807607edba7",
   "metadata": {},
   "source": [
    "# Filter compact dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f57846-79af-4cbd-a827-b4f5c73c504a",
   "metadata": {},
   "source": [
    "This file reads the compact dataframes and filters for specific records (e.g. for moisture sensitive records). \n",
    "The filtered dataset is saved in a separate directory and can be loaded for further analysis or plotting etc.\n",
    "\n",
    "Author: Lucie Luecke\n",
    "\n",
    "Date produced: 21/01/2025\n",
    "\n",
    "Input: \n",
    "reads dataframe with the following keys:\n",
    "  - ```archiveType```\n",
    "  - ```dataSetName```\n",
    "  - ```datasetId```\n",
    "  - ```geo_meanElev```\n",
    "  - ```geo_meanLat```\n",
    "  - ```geo_meanLon```\n",
    "  - ```geo_siteName```\n",
    "  - ```interpretation_direction``` (new in v2.0)\n",
    "  - ```interpretation_variable```\n",
    "  - ```interpretation_variableDetail```\n",
    "  - ```interpretation_seasonality``` (new in v2.0)\n",
    "  - ```originalDataURL```\n",
    "  - ```originalDatabase```\n",
    "  - ```paleoData_notes```\n",
    "  - ```paleoData_proxy```\n",
    "  - ```paleoData_sensorSpecies```\n",
    "  - ```paleoData_units```\n",
    "  - ```paleoData_values```\n",
    "  - ```paleoData_variableName```\n",
    "  - ```year```\n",
    "  - ```yearUnits```\n",
    "  - (optional: `DuplicateDetails`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61e97d-f071-4f7c-b376-40fa56555a94",
   "metadata": {},
   "source": [
    "## Set up working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5763910-065a-4888-ba43-21b5e01d4ada",
   "metadata": {},
   "source": [
    "Make sure the repo_root is added correctly, it should be: your_root_dir/dod2k\n",
    "This should be the working directory throughout this notebook (and all other notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c4911b-41ea-4367-bbcc-ce112c5fbd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /home/jupyter-lluecke/compile_proxy_database_v2.2/dod2k\n",
      "Working directory matches repo root. \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path (works from any notebook in notebooks/)\n",
    "# the repo_root should be the parent directory of the notebooks folder\n",
    "current_dir = Path().resolve()\n",
    "# Determine repo root\n",
    "if current_dir.name == 'dod2k':\n",
    "    repo_root = current_dir\n",
    "elif current_dir.parent.name == 'dod2k':\n",
    "    repo_root = current_dir.parent\n",
    "else:\n",
    "    raise Exception('Please review the repo root structure (see first cell).')\n",
    "\n",
    "# Update cwd and path only if needed\n",
    "if os.getcwd() != str(repo_root):\n",
    "    os.chdir(repo_root)\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "if str(os.getcwd())==str(repo_root):\n",
    "    print(f\"Working directory matches repo root. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc44c46-7c88-4561-8694-1251f8c2b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dod2k_utilities import ut_functions as utf # contains utility functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc0e2c-d3c6-40da-9e4f-5e015073d7c6",
   "metadata": {},
   "source": [
    "## read dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3750b68-6578-42ec-b432-275d3d3758d7",
   "metadata": {},
   "source": [
    "Read compact dataframe for filtering.\n",
    "\n",
    "{db_name} refers to the database, including\n",
    "  - database of databases:\n",
    "    - dod2k_dupfree_dupfree (twice filtered for duplicates)\n",
    "    - dod2k_dupfree_dupfree_MT (twice filtered for duplicates and filtered for MT sensitive proxies only)\n",
    "    - dod2k_dupfree (once filtered for duplicates)\n",
    "    - dod2k (NOT filtered for duplicates, only fusion of the input databases)\n",
    "  - original databases:\n",
    "    - fe23\n",
    "    - ch2k\n",
    "    - sisal\n",
    "    - pages2k\n",
    "    - iso2k\n",
    "\n",
    "All compact dataframes are saved in {repo_root}/data/{db_name} as {db_name}_compact.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e017f834-97a3-4ed4-a66d-9d57c440bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FE23 (Breitenmoser et al. (2014))' 'CoralHydro2k v1.0.0'\n",
      " 'dod2k_composite_standardised' 'Iso2k v1.0.1'\n",
      " 'PAGES2k v2.0.0 (Ocn_103 updated with Dee et al. 2020)' 'SISAL v3']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4516 entries, 0 to 4515\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   archiveType                           4516 non-null   object \n",
      " 1   climateInterpretation_variable        4516 non-null   object \n",
      " 2   climateInterpretation_variableDetail  4516 non-null   object \n",
      " 3   dataSetName                           4516 non-null   object \n",
      " 4   datasetId                             4516 non-null   object \n",
      " 5   duplicateDetails                      4516 non-null   object \n",
      " 6   geo_meanElev                          4433 non-null   float32\n",
      " 7   geo_meanLat                           4516 non-null   float32\n",
      " 8   geo_meanLon                           4516 non-null   float32\n",
      " 9   geo_siteName                          4516 non-null   object \n",
      " 10  originalDataURL                       4516 non-null   object \n",
      " 11  originalDatabase                      4516 non-null   object \n",
      " 12  paleoData_notes                       4516 non-null   object \n",
      " 13  paleoData_proxy                       4516 non-null   object \n",
      " 14  paleoData_sensorSpecies               4516 non-null   object \n",
      " 15  paleoData_units                       4516 non-null   object \n",
      " 16  paleoData_values                      4516 non-null   object \n",
      " 17  year                                  4516 non-null   object \n",
      " 18  yearUnits                             4516 non-null   object \n",
      "dtypes: float32(3), object(16)\n",
      "memory usage: 617.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_name = 'dod2k_v1.2'\n",
    "\n",
    "df = utf.load_compact_dataframe_from_csv(db_name)\n",
    "print(df.originalDatabase.unique())\n",
    "df.name = db_name\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ccce94-a8bf-4b7f-bd14-adedda715b0f",
   "metadata": {},
   "source": [
    "## filter dataframe for specific record types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85a217-339f-4094-b923-a00ba0dd65df",
   "metadata": {},
   "source": [
    "Here you can filter the dataframe for specific record types. Below is an example where we filter for interpretation_variable=temperature. \n",
    "\n",
    "This could be done with any column and any value (e.g. for a specific archive type, etc.)\n",
    "\n",
    "Please look at the examples below which are commented out for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a67160c-2b5a-4e8e-87cc-0f53f612bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to filter for specific metadata, e.g. temperature or moisture records, run this:\n",
    "\n",
    "\n",
    "# ---> interpretation_variable\n",
    "# e.g.\n",
    "\n",
    "# # filter for >>moisture<< sensitive records only (also include records which are moisture and temperature sensitive)\n",
    "df_filter = df.loc[(df['interpretation_variable']=='moisture')|(df['interpretation_variable']=='temperature+moisture')]\n",
    "\n",
    "# # filter for >>exclusively moisture<< sensitive records only (without t+m)\n",
    "# df_filter = df.loc[(df['interpretation_variable']=='moisture')]\n",
    "\n",
    "# # filter for >>temperature<< sensitive records only (also include records which are moisture and temperature sensitive)\n",
    "# df_filter = df.loc[(df['interpretation_variable']=='temperature')|(df['interpretation_variable']=='temperature+moisture'])]\n",
    "\n",
    "# # filter for >>exclusively temperature<< sensitive records only (without t+m)\n",
    "# df_filter = df.loc[(df['interpretation_variable']=='temperature')]\n",
    "\n",
    "# ---> archiveType and paleoData_proxy\n",
    "# e.g.\n",
    "\n",
    "# # filter for specific proxy type, e.g. archiveType='speleothem' and paleoData_proxy='d18O'\n",
    "# df_filter = df.loc[(df['archiveType']=='speleothem')&(df['paleoData_proxy']=='d18O')]\n",
    "\n",
    "\n",
    "# ---> paleoData_proxy only\n",
    "# e.g. \n",
    "\n",
    "# df_filter = df.loc[(df['paleoData_proxy']=='MXD')]\n",
    "\n",
    "# etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d4fde-22db-4955-88f1-9a9a78ea2fda",
   "metadata": {},
   "source": [
    "IMPORTANT: the database name needs to be adjusted according to the filtering.\n",
    "\n",
    "Please add an identifier to the dataframe name which will be used for displaying and savng the data. \n",
    "\n",
    "Make sure it is different from the original db_name.\n",
    "\n",
    "As df.name is used for saving the filtered data it is crucial that it differs from the original db_name otherwise the data will get overwritten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b4af5f-1aba-4ade-aec6-ce76b9648741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dod2k_v1.2_filtered_M\n"
     ]
    }
   ],
   "source": [
    "# df needs name reassigned as it gets lost otherwise after assigning new value to df (through the filtering above)\n",
    "\n",
    "# for the M+T filtered example, revise df.name to _filtered_MT\n",
    "df_filter.name = db_name + \"_filtered_M\" \n",
    "print(df_filter.name)\n",
    "\n",
    "assert df_filter.name!=db_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc017188-c30b-4866-b2a3-a0c6b85a7dd5",
   "metadata": {},
   "source": [
    "Display the filtered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d999ba0f-a2e4-42ec-9e30-a4644230281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1597 entries, 2 to 4513\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   archiveType                           1597 non-null   object \n",
      " 1   climateInterpretation_variable        1597 non-null   object \n",
      " 2   climateInterpretation_variableDetail  1597 non-null   object \n",
      " 3   dataSetName                           1597 non-null   object \n",
      " 4   datasetId                             1597 non-null   object \n",
      " 5   duplicateDetails                      1597 non-null   object \n",
      " 6   geo_meanElev                          1565 non-null   float32\n",
      " 7   geo_meanLat                           1597 non-null   float32\n",
      " 8   geo_meanLon                           1597 non-null   float32\n",
      " 9   geo_siteName                          1597 non-null   object \n",
      " 10  originalDataURL                       1597 non-null   object \n",
      " 11  originalDatabase                      1597 non-null   object \n",
      " 12  paleoData_notes                       1597 non-null   object \n",
      " 13  paleoData_proxy                       1597 non-null   object \n",
      " 14  paleoData_sensorSpecies               1597 non-null   object \n",
      " 15  paleoData_units                       1597 non-null   object \n",
      " 16  paleoData_values                      1597 non-null   object \n",
      " 17  year                                  1597 non-null   object \n",
      " 18  yearUnits                             1597 non-null   object \n",
      "dtypes: float32(3), object(16)\n",
      "memory usage: 230.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_filter.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f4369-79be-49eb-9e79-6f06f82f7eb5",
   "metadata": {},
   "source": [
    "## save filtered dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677dcace-d7c0-4b6d-a2a3-1cb69767c471",
   "metadata": {},
   "source": [
    "Saves the filtered dataframe in:\n",
    "\n",
    "{repo_root}/data/{df_filter.name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f447639-6704-4699-bba3-e98acb6c8a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new directory if dir does not exist\n",
    "path = '/data/'+df_filter.name\n",
    "os.makedirs(os.getcwd()+path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765ab8e4-dbcd-4778-baa1-86e71db7b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pickle\n",
    "df_filter.to_pickle(f'data/{df_filter.name}/{df_filter.name}_compact.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0a2800-3fe6-416d-af95-e7be21d3abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METADATA: archiveType, climateInterpretation_variable, climateInterpretation_variableDetail, dataSetName, datasetId, duplicateDetails, geo_meanElev, geo_meanLat, geo_meanLon, geo_siteName, originalDataURL, originalDatabase, paleoData_notes, paleoData_proxy, paleoData_sensorSpecies, paleoData_units, yearUnits\n",
      "Saved to /home/jupyter-lluecke/compile_proxy_database_v2.2/dod2k/data/dod2k_v1.2_filtered_M/dod2k_v1.2_filtered_M_compact_%s.csv\n"
     ]
    }
   ],
   "source": [
    "# save csv\n",
    "utf.write_compact_dataframe_to_csv(df_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4446855-345b-4ae7-a7ce-0107cb0fdc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1597 entries, 0 to 1596\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   archiveType                           1597 non-null   object \n",
      " 1   climateInterpretation_variable        1597 non-null   object \n",
      " 2   climateInterpretation_variableDetail  1597 non-null   object \n",
      " 3   dataSetName                           1597 non-null   object \n",
      " 4   datasetId                             1597 non-null   object \n",
      " 5   duplicateDetails                      1597 non-null   object \n",
      " 6   geo_meanElev                          1565 non-null   float32\n",
      " 7   geo_meanLat                           1597 non-null   float32\n",
      " 8   geo_meanLon                           1597 non-null   float32\n",
      " 9   geo_siteName                          1597 non-null   object \n",
      " 10  originalDataURL                       1597 non-null   object \n",
      " 11  originalDatabase                      1597 non-null   object \n",
      " 12  paleoData_notes                       1597 non-null   object \n",
      " 13  paleoData_proxy                       1597 non-null   object \n",
      " 14  paleoData_sensorSpecies               1597 non-null   object \n",
      " 15  paleoData_units                       1597 non-null   object \n",
      " 16  paleoData_values                      1597 non-null   object \n",
      " 17  year                                  1597 non-null   object \n",
      " 18  yearUnits                             1597 non-null   object \n",
      "dtypes: float32(3), object(16)\n",
      "memory usage: 218.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# load dataframe\n",
    "utf.load_compact_dataframe_from_csv(df_filter.name).info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cfr-env)",
   "language": "python",
   "name": "cfr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
