{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8b9506-0168-46c3-9fae-a807607edba7",
   "metadata": {},
   "source": [
    "# Filter compact dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f57846-79af-4cbd-a827-b4f5c73c504a",
   "metadata": {},
   "source": [
    "This file reads the compact dataframes and filters for specific records (e.g. for moisture sensitive records). \n",
    "The filtered dataset is saved in a separate directory and can be loaded for further analysis or plotting etc.\n",
    "\n",
    "Author: Lucie Luecke\n",
    "\n",
    "Date produced: 21/01/2025\n",
    "\n",
    "Input: \n",
    "reads dataframe with the following keys:\n",
    "  - ```archiveType```\n",
    "  - ```dataSetName```\n",
    "  - ```datasetId```\n",
    "  - ```geo_meanElev```\n",
    "  - ```geo_meanLat```\n",
    "  - ```geo_meanLon```\n",
    "  - ```geo_siteName```\n",
    "  - ```interpretation_direction``` (new in v2.0)\n",
    "  - ```interpretation_variable```\n",
    "  - ```interpretation_variableDetail```\n",
    "  - ```interpretation_seasonality``` (new in v2.0)\n",
    "  - ```originalDataURL```\n",
    "  - ```originalDatabase```\n",
    "  - ```paleoData_notes```\n",
    "  - ```paleoData_proxy```\n",
    "  - ```paleoData_sensorSpecies```\n",
    "  - ```paleoData_units```\n",
    "  - ```paleoData_values```\n",
    "  - ```paleoData_variableName```\n",
    "  - ```year```\n",
    "  - ```yearUnits```\n",
    "  - (optional: `DuplicateDetails`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61e97d-f071-4f7c-b376-40fa56555a94",
   "metadata": {},
   "source": [
    "## Set up working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5763910-065a-4888-ba43-21b5e01d4ada",
   "metadata": {},
   "source": [
    "Make sure the repo_root is added correctly, it should be: your_root_dir/dod2k\n",
    "This should be the working directory throughout this notebook (and all other notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c4911b-41ea-4367-bbcc-ce112c5fbd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /home/jupyter-lluecke/dod2k\n",
      "Working directory matches repo root. \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path (works from any notebook in notebooks/)\n",
    "# the repo_root should be the parent directory of the notebooks folder\n",
    "current_dir = Path().resolve()\n",
    "# Determine repo root\n",
    "if current_dir.name == 'dod2k':\n",
    "    repo_root = current_dir\n",
    "elif current_dir.parent.name == 'dod2k':\n",
    "    repo_root = current_dir.parent\n",
    "else:\n",
    "    raise Exception('Please review the repo root structure (see first cell).')\n",
    "\n",
    "# Update cwd and path only if needed\n",
    "if os.getcwd() != str(repo_root):\n",
    "    os.chdir(repo_root)\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "if str(os.getcwd())==str(repo_root):\n",
    "    print(f\"Working directory matches repo root. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc44c46-7c88-4561-8694-1251f8c2b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dod2k_utilities import ut_functions as utf # contains utility functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc0e2c-d3c6-40da-9e4f-5e015073d7c6",
   "metadata": {},
   "source": [
    "## read dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3750b68-6578-42ec-b432-275d3d3758d7",
   "metadata": {},
   "source": [
    "Read compact dataframe.\n",
    "\n",
    "{db_name} refers to the database, including e.g.\n",
    "  - database of databases:\n",
    "    - dod2k_v2.0 (dod2k: duplicate free, merged database)\n",
    "    - all_merged (NOT filtered for duplicates, only fusion of the input databases)\n",
    "  - original databases:\n",
    "    - fe23\n",
    "    - ch2k\n",
    "    - sisal\n",
    "    - pages2k\n",
    "    - iso2k\n",
    "\n",
    "All compact dataframes are saved in {repo_root}/data/{db_name} as {db_name}_compact.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e017f834-97a3-4ed4-a66d-9d57c440bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PAGES 2k v2.2.0' 'FE23 (Breitenmoser et al. (2014))'\n",
      " 'CoralHydro2k v1.0.1' 'Iso2k v1.1.2' 'SISAL v3' 'dod2k_composite_z']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4957 entries, 0 to 4956\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   archiveType                    4957 non-null   object \n",
      " 1   dataSetName                    4957 non-null   object \n",
      " 2   datasetId                      4957 non-null   object \n",
      " 3   duplicateDetails               4957 non-null   object \n",
      " 4   geo_meanElev                   4875 non-null   float32\n",
      " 5   geo_meanLat                    4957 non-null   float32\n",
      " 6   geo_meanLon                    4957 non-null   float32\n",
      " 7   geo_siteName                   4957 non-null   object \n",
      " 8   interpretation_direction       4957 non-null   object \n",
      " 9   interpretation_seasonality     4957 non-null   object \n",
      " 10  interpretation_variable        4957 non-null   object \n",
      " 11  interpretation_variableDetail  4957 non-null   object \n",
      " 12  originalDataURL                4957 non-null   object \n",
      " 13  originalDatabase               4957 non-null   object \n",
      " 14  paleoData_notes                4957 non-null   object \n",
      " 15  paleoData_proxy                4957 non-null   object \n",
      " 16  paleoData_sensorSpecies        4957 non-null   object \n",
      " 17  paleoData_units                4957 non-null   object \n",
      " 18  paleoData_values               4957 non-null   object \n",
      " 19  paleoData_variableName         4957 non-null   object \n",
      " 20  year                           4957 non-null   object \n",
      " 21  yearUnits                      4957 non-null   object \n",
      "dtypes: float32(3), object(19)\n",
      "memory usage: 794.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_name = 'dod2k_v2.0'\n",
    "\n",
    "df = utf.load_compact_dataframe_from_csv(db_name)\n",
    "print(df.originalDatabase.unique())\n",
    "df.name = db_name\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ccce94-a8bf-4b7f-bd14-adedda715b0f",
   "metadata": {},
   "source": [
    "## filter dataframe for specific record types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85a217-339f-4094-b923-a00ba0dd65df",
   "metadata": {},
   "source": [
    "Here you can filter the dataframe for specific record types. Below is an example where we filter for interpretation_variable=temperature. \n",
    "\n",
    "This could be done with any column and any value (e.g. for a specific archive type, etc.)\n",
    "\n",
    "Please look at the examples below which are commented out for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a67160c-2b5a-4e8e-87cc-0f53f612bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to filter for specific metadata, e.g. temperature or moisture records, run this:\n",
    "\n",
    "\n",
    "# ---> interpretation_variable\n",
    "# e.g.\n",
    "\n",
    "# # filter for >>moisture<< sensitive records only (also include records which are moisture and temperature sensitive)\n",
    "# df_filter = df.loc[(df['interpretation_variable']=='moisture')|(df['interpretation_variable']=='temperature+moisture')]\n",
    "# df_filter.name = db_name + \"_filtered_M_TM\" \n",
    "\n",
    "\n",
    "# filter for >>exclusively moisture<< sensitive records only (without t+m)\n",
    "df_filter = df.loc[(df['interpretation_variable']=='moisture')]\n",
    "df_filter.name = db_name + \"_filtered_M\" \n",
    "\n",
    "\n",
    "# # filter for >>temperature<< sensitive records only (also include records which are moisture and temperature sensitive)\n",
    "# df_filter = df.loc[(df['interpretation_variable']=='temperature')|(df['interpretation_variable']=='temperature+moisture')]\n",
    "# df_filter.name = db_name + \"_filtered_T_TM\" \n",
    "\n",
    "# # filter for >>exclusively temperature<< sensitive records only (without t+m)\n",
    "# df_filter = df.loc[(df['interpretation_variable']=='temperature')]\n",
    "# df_filter.name = db_name + \"_filtered_T\" \n",
    "\n",
    "\n",
    "# ---> archiveType and paleoData_proxy\n",
    "# e.g.\n",
    "\n",
    "# # filter for specific proxy type, e.g. archiveType='speleothem' and paleoData_proxy='d18O'\n",
    "# df_filter = df.loc[(df['archiveType']=='speleothem')&(df['paleoData_proxy']=='d18O')]\n",
    "# df_filter.name = db_name + \"_filtered_speleo_d18O\" \n",
    "\n",
    "# # filter for specific proxy type, e.g. archiveType='speleothem' only\n",
    "# df_filter = df.loc[(df['archiveType']=='speleothem')]\n",
    "# df_filter.name = db_name + \"_filtered_speleothem\" \n",
    "\n",
    "\n",
    "# ---> paleoData_proxy only\n",
    "# e.g. \n",
    "\n",
    "# df_filter = df.loc[(df['paleoData_proxy']=='MXD')]\n",
    "\n",
    "# etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d4fde-22db-4955-88f1-9a9a78ea2fda",
   "metadata": {},
   "source": [
    "IMPORTANT: the database name needs to be adjusted according to the filtering.\n",
    "\n",
    "Please add an identifier to the dataframe name which will be used for displaying and savng the data. \n",
    "\n",
    "Make sure it is different from the original db_name.\n",
    "\n",
    "As df.name is used for saving the filtered data it is crucial that it differs from the original db_name otherwise the data will get overwritten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b4af5f-1aba-4ade-aec6-ce76b9648741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dod2k_v2.0_filtered_M\n"
     ]
    }
   ],
   "source": [
    "# df needs name reassigned as it gets lost otherwise after assigning new value to df (through the filtering above)\n",
    "\n",
    "# for the M+T filtered example, revise df.name to _filtered_MT\n",
    "print(df_filter.name)\n",
    "\n",
    "assert df_filter.name!=db_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc017188-c30b-4866-b2a3-a0c6b85a7dd5",
   "metadata": {},
   "source": [
    "Display the filtered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d999ba0f-a2e4-42ec-9e30-a4644230281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 996 entries, 303 to 4421\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   archiveType                    996 non-null    object \n",
      " 1   dataSetName                    996 non-null    object \n",
      " 2   datasetId                      996 non-null    object \n",
      " 3   duplicateDetails               996 non-null    object \n",
      " 4   geo_meanElev                   986 non-null    float32\n",
      " 5   geo_meanLat                    996 non-null    float32\n",
      " 6   geo_meanLon                    996 non-null    float32\n",
      " 7   geo_siteName                   996 non-null    object \n",
      " 8   interpretation_direction       996 non-null    object \n",
      " 9   interpretation_seasonality     996 non-null    object \n",
      " 10  interpretation_variable        996 non-null    object \n",
      " 11  interpretation_variableDetail  996 non-null    object \n",
      " 12  originalDataURL                996 non-null    object \n",
      " 13  originalDatabase               996 non-null    object \n",
      " 14  paleoData_notes                996 non-null    object \n",
      " 15  paleoData_proxy                996 non-null    object \n",
      " 16  paleoData_sensorSpecies        996 non-null    object \n",
      " 17  paleoData_units                996 non-null    object \n",
      " 18  paleoData_values               996 non-null    object \n",
      " 19  paleoData_variableName         996 non-null    object \n",
      " 20  year                           996 non-null    object \n",
      " 21  yearUnits                      996 non-null    object \n",
      "dtypes: float32(3), object(19)\n",
      "memory usage: 167.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_filter.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f4369-79be-49eb-9e79-6f06f82f7eb5",
   "metadata": {},
   "source": [
    "## save filtered dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677dcace-d7c0-4b6d-a2a3-1cb69767c471",
   "metadata": {},
   "source": [
    "Saves the filtered dataframe in:\n",
    "\n",
    "{repo_root}/data/{df_filter.name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f447639-6704-4699-bba3-e98acb6c8a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new directory if dir does not exist\n",
    "path = '/data/'+df_filter.name\n",
    "os.makedirs(os.getcwd()+path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765ab8e4-dbcd-4778-baa1-86e71db7b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pickle\n",
    "df_filter.to_pickle(f'data/{df_filter.name}/{df_filter.name}_compact.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0a2800-3fe6-416d-af95-e7be21d3abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METADATA: datasetId, archiveType, dataSetName, duplicateDetails, geo_meanElev, geo_meanLat, geo_meanLon, geo_siteName, interpretation_direction, interpretation_seasonality, interpretation_variable, interpretation_variableDetail, originalDataURL, originalDatabase, paleoData_notes, paleoData_proxy, paleoData_sensorSpecies, paleoData_units, paleoData_variableName, yearUnits\n",
      "Saved to /home/jupyter-lluecke/dod2k/data/dod2k_v2.0_filtered_M/dod2k_v2.0_filtered_M_compact_%s.csv\n"
     ]
    }
   ],
   "source": [
    "# save csv\n",
    "utf.write_compact_dataframe_to_csv(df_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4446855-345b-4ae7-a7ce-0107cb0fdc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 996 entries, 0 to 995\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   archiveType                    996 non-null    object \n",
      " 1   dataSetName                    996 non-null    object \n",
      " 2   datasetId                      996 non-null    object \n",
      " 3   duplicateDetails               996 non-null    object \n",
      " 4   geo_meanElev                   986 non-null    float32\n",
      " 5   geo_meanLat                    996 non-null    float32\n",
      " 6   geo_meanLon                    996 non-null    float32\n",
      " 7   geo_siteName                   996 non-null    object \n",
      " 8   interpretation_direction       996 non-null    object \n",
      " 9   interpretation_seasonality     996 non-null    object \n",
      " 10  interpretation_variable        996 non-null    object \n",
      " 11  interpretation_variableDetail  996 non-null    object \n",
      " 12  originalDataURL                996 non-null    object \n",
      " 13  originalDatabase               996 non-null    object \n",
      " 14  paleoData_notes                996 non-null    object \n",
      " 15  paleoData_proxy                996 non-null    object \n",
      " 16  paleoData_sensorSpecies        996 non-null    object \n",
      " 17  paleoData_units                996 non-null    object \n",
      " 18  paleoData_values               996 non-null    object \n",
      " 19  paleoData_variableName         996 non-null    object \n",
      " 20  year                           996 non-null    object \n",
      " 21  yearUnits                      996 non-null    object \n",
      "dtypes: float32(3), object(19)\n",
      "memory usage: 159.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# load dataframe\n",
    "utf.load_compact_dataframe_from_csv(df_filter.name).info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cfr-env)",
   "language": "python",
   "name": "cfr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
