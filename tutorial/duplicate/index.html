
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Database of databases">
      
      
      
      
        <link rel="prev" href="../load_merge/">
      
      
        <link rel="next" href="../from_scratch/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Duplicate Detection - DoD2k Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#run-the-duplicate-detection-workflow-to-generate-a-duplicate-free-dataframe" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="DoD2k Documentation" class="md-header__button md-logo" aria-label="DoD2k Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            DoD2k Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Duplicate Detection
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/lluecke/dod2k" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    lluecke/dod2k
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../dod2k/" class="md-tabs__link">
        
  
  
    
  
  DoD2k

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../getting_started/" class="md-tabs__link">
          
  
  
  Getting started

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../api/" class="md-tabs__link">
        
  
  
    
  
  API Reference

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../notebooks/" class="md-tabs__link">
          
  
  
  Notebooks

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="DoD2k Documentation" class="md-nav__button md-logo" aria-label="DoD2k Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    DoD2k Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/lluecke/dod2k" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    lluecke/dod2k
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dod2k/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DoD2k
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Getting started
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Getting started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quickstart
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../use_dod2k/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Explore DoD2k
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../load_merge/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Load and merge original databases
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Duplicate Detection
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Duplicate Detection
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#required-columns" class="md-nav__link">
    <span class="md-ellipsis">
      Required columns
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-1-duplicate-detection-dup_detectionipynb" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1: Duplicate detection (dup_detection.ipynb)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 1: Duplicate detection (dup_detection.ipynb)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-set-up-working-environment" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Set up working environment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-load-the-compact-dataframe" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Load the compact dataframe
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-run-the-duplicate-detection-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 Run the duplicate detection algorithm
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-2-duplicate-decisions-dup_decisionipynb" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Duplicate decisions (dup_decision.ipynb)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 2: Duplicate decisions (dup_decision.ipynb)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-initialisation" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Initialisation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-hierarchy-for-duplicate-removal-for-identical-duplicates" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Hierarchy for duplicate removal for identical duplicates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-duplicate-decision-process" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Duplicate decision process
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-3-duplicate-removal-dup_removalipynb" class="md-nav__link">
    <span class="md-ellipsis">
      Step 3: Duplicate removal (dup_removal.ipynb)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 3: Duplicate removal (dup_removal.ipynb)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-initialisation" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Initialisation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-load-duplicate-decisions-from-csv" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Load duplicate decisions from csv
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-implement-duplicate-decisions" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Implement duplicate decisions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 Implement duplicate decisions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#332-records-to-be-composited" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.2. Records to be composited
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#333-check-for-multiple-duplicate-records-with-different-decisions" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.3. Check for multiple duplicate records with different decisions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-save-duplicate-free-dataframe" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 Save duplicate free dataframe
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../from_scratch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Generate DoD2k from scratch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../applications/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Applications
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Notebooks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Notebooks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/df_info/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Display entries of compact dataframe column by column
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/df_plot_dod2k/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Visualise DoD2k
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/df_filter/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Filter compact dataframe
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/dup_detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Duplicate detection - step 1: find the potential duplicates
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/dup_decision/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Duplicate detection - step 2: review and decide on candidate pairs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/dup_removal/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Duplicate detection - step 3: remove true duplicates
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/load_pages2k/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Load PAGES 2k
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/load_sisal/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Load SISAL
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/load_ch2k/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Load CoralHydro 2k
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/load_iso2k/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Load Iso 2k
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/load_fe23/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Load FE23
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#required-columns" class="md-nav__link">
    <span class="md-ellipsis">
      Required columns
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-1-duplicate-detection-dup_detectionipynb" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1: Duplicate detection (dup_detection.ipynb)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 1: Duplicate detection (dup_detection.ipynb)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-set-up-working-environment" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Set up working environment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-load-the-compact-dataframe" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Load the compact dataframe
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-run-the-duplicate-detection-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 Run the duplicate detection algorithm
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-2-duplicate-decisions-dup_decisionipynb" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Duplicate decisions (dup_decision.ipynb)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 2: Duplicate decisions (dup_decision.ipynb)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-initialisation" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Initialisation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-hierarchy-for-duplicate-removal-for-identical-duplicates" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Hierarchy for duplicate removal for identical duplicates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-duplicate-decision-process" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Duplicate decision process
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-3-duplicate-removal-dup_removalipynb" class="md-nav__link">
    <span class="md-ellipsis">
      Step 3: Duplicate removal (dup_removal.ipynb)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 3: Duplicate removal (dup_removal.ipynb)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-initialisation" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Initialisation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-load-duplicate-decisions-from-csv" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Load duplicate decisions from csv
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-implement-duplicate-decisions" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Implement duplicate decisions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 Implement duplicate decisions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#332-records-to-be-composited" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.2. Records to be composited
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#333-check-for-multiple-duplicate-records-with-different-decisions" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.3. Check for multiple duplicate records with different decisions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-save-duplicate-free-dataframe" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 Save duplicate free dataframe
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="run-the-duplicate-detection-workflow-to-generate-a-duplicate-free-dataframe"><strong>Run the duplicate detection workflow to generate a duplicate free dataframe</strong></h1>
<p>This workflow runs a duplicate detection, decision and removal algorithm to generate a duplicate free dataframe. </p>
<h2 id="required-columns">Required columns</h2>
<p>The input dataframe must have the following columns:</p>
<div class="grid" style="grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 0.5rem;">
<ul>
<li><code>archiveType</code>       (used for duplicate detection algorithm)</li>
<li><code>dataSetName</code></li>
<li><code>datasetId</code></li>
<li><code>geo_meanElev</code>      (used for duplicate detection algorithm)</li>
<li><code>geo_meanLat</code>       (used for duplicate detection algorithm)</li>
<li><code>geo_meanLon</code>       (used for duplicate detection algorithm)</li>
<li><code>geo_siteName</code>      (used for duplicate detection algorithm)</li>
<li><code>interpretation_direction</code></li>
<li><code>interpretation_seasonality</code></li>
<li><code>interpretation_variable</code></li>
<li><code>interpretation_variableDetails</code></li>
<li><code>originalDataURL</code></li>
<li><code>originalDatabase</code></li>
<li><code>paleoData_notes</code></li>
<li><code>paleoData_proxy</code>   (used for duplicate detection algorithm)</li>
<li><code>paleoData_units</code></li>
<li><code>paleoData_values</code>  (used for duplicate detection algorithm, test for correlation, RMSE, correlation of 1st difference, RMSE of 1st difference)</li>
<li><code>paleoData_variableName</code></li>
<li><code>year</code>              (used for duplicate detection algorithm)</li>
<li><code>yearUnits</code></li>
</ul>
</div>
<div class="admonition info">
<p class="admonition-title">Output Location</p>
<p>All outputs are saved as <code>csv</code> in the directory <code>data/DATABASENAME/dup_detection</code>.</p>
</div>
<hr />
<h2 id="step-1-duplicate-detection-dup_detectionipynb"><strong>Step 1: Duplicate detection (<code>dup_detection.ipynb</code>)</strong></h2>
<p><strong>Notebook:</strong> <a href="../../notebooks/dup_detection/"><code>dup_detection.ipynb</code></a></p>
<p>This interactive notebook (<code>dup_detection.ipynb</code>) runs a duplicate detection algorithm for a specific database. </p>
<h3 id="11-set-up-working-environment">1.1 Set up working environment</h3>
<p>Make sure the repo_root is added correctly: <code>your_root_dir/dod2k</code>
This should be the working directory throughout this notebook (and all other notebooks).
The following libraries are required to run this notebook</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">dod2k_utilities</span><span class="w"> </span><span class="kn">import</span> <span class="n">ut_functions</span> <span class="k">as</span> <span class="n">utf</span> <span class="c1"># contains utility functions</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dod2k_utilities</span><span class="w"> </span><span class="kn">import</span> <span class="n">ut_duplicate_search</span> <span class="k">as</span> <span class="n">dup</span> <span class="c1"># contains utility functions</span>
</code></pre></div>
<h3 id="12-load-the-compact-dataframe">1.2 Load the compact dataframe</h3>
<p>Define the dataset which needs to be screened for duplicates. Input files for the duplicate detection mechanism need to be compact dataframes (<code>pandas</code> dataframes with standardised columns and entry formatting). </p>
<p>The function <code>load_compact_dataframe_from_csv</code> loads the dataframe from a <code>csv</code> file from <code>data\DB\</code>, with <code>DB</code> the name of the database. The database name (<code>db_name</code>) can be 
- <code>pages2k</code>
- <code>ch2k</code>
- <code>iso2k</code>
- <code>sisal</code>
- <code>fe23</code></p>
<p>for the individual databases, or </p>
<ul>
<li><code>all_merged</code></li>
</ul>
<p>to load the merged database of all individual databases, or can be any user defined compact dataframe.</p>
<p>Load the dataframe using
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">db_name</span><span class="o">=</span><span class="s1">&#39;all_merged&#39;</span> 
<span class="n">df</span> <span class="o">=</span> <span class="n">utf</span><span class="o">.</span><span class="n">load_compact_dataframe_from_csv</span><span class="p">(</span><span class="n">db_name</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="13-run-the-duplicate-detection-algorithm">1.3 Run the duplicate detection algorithm</h3>
<p>Now run the first part of the duplicate detection algorithm, which goes through each candidate pair and evaluates the pairs according to a defined set of criteria.</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">dup</span><span class="o">.</span><span class="n">find_duplicates_optimized</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">n_points_thresh</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>
<p><strong>Output:</strong> <code>data/DB/dup_detection/dup_detection_candidates_DB.csv</code></p>
<div class="admonition abstract">
<p class="admonition-title">Detection Criteria</p>
<ul>
<li><strong>metadata criteria</strong>:</li>
<li>archive types (<code>archiveType</code>) must be identical</li>
<li>proxy types (<code>paleoData_proxy</code>) must be identical</li>
<li><strong>geographical criteria</strong>:</li>
<li>elevation (<code>geo_meanElev</code>) similar, within defined tolerance (use kwarg <code>elevation_tolerance</code>, defaults to 0)</li>
<li>latitude and longtitude (<code>geo_meanLat</code> and <code>geo_meanLon</code>) similar, within defined tolerance in km (use kwarg <code>dist_tolerance_km</code>, defaults to 8 km)</li>
<li><strong>overlap criterion</strong>:</li>
<li>time must overlap for at least $n$ points (use kwarg <code>n_points_thresh</code> to modify, defaults to $n=10$) unless at least one of the record is shorter than <code>n_points_thresh</code> </li>
<li><strong>site criterion</strong>:</li>
<li>there must be some overlap in the site name (<code>geo_siteName</code>)</li>
<li><strong>correlation criteria</strong>:</li>
<li>correlation between the overlapping period must be greater than defined threshold (use <code>corr_thresh</code> to modify, defaults to 0.9) or correlation of first difference must be greater than defined threshold (use <code>corr_diff_thresh</code> to modify, defaults to 0.9)</li>
<li>RMSE of overlapping period must be smaller than defined threshold (use <code>rmse_thresh</code> to modify, defaults to 0.1) or RMSE of first difference must be smaller than defined threshold (use <code>rmse_diff_thresh</code> to modify, defaults to 0.1)</li>
<li><strong>URL criterion</strong>:</li>
<li>URLs (<code>originalDataURL</code>) must be identical if both records originate from the same database (<code>originalDatabase</code> must be identical)</li>
</ul>
</div>
<div class="admonition warning">
<p class="admonition-title">Flagging Logic</p>
<p><strong>A potential duplicate candidate pair is flagged, if all of these criteria are satisfied OR the correlation between the candidates is particularly high (&gt;0.98), while there is sufficient overlap (as defined by the overlap criterion).</strong></p>
</div>
<details class="tip" open="open">
<summary>Tip for large databases</summary>
<p>The duplicate detection algorithm can take a while to run, especially for large databases (such as the merged database with over 5000 records). 
Instead of running this notebook interactively, it might therefore be better to execute it as a python script via the command line.</p>
<p>In order to do this, run</p>
<div class="highlight"><span class="filename">bash</span><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>~/dod2k_v2.0/dod2k
mkdir<span class="w"> </span>-p<span class="w"> </span>scripts
jupyter<span class="w"> </span>nbconvert<span class="w"> </span>--to<span class="w"> </span>python<span class="w"> </span>notebooks/dup_detection.ipynb<span class="w"> </span>--stdout<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>sed<span class="w"> </span><span class="s1">&#39;s/^get_ipython()/# get_ipython()/&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>sed<span class="w"> </span><span class="s1">&#39;s/^\([[:space:]]*\)%/\1# %/&#39;</span><span class="w"> </span>&gt;<span class="w"> </span>scripts/dup_detection.py
</code></pre></div>
<p>This generates a script <code>dup_detection.py</code> from the command line. Make sure you have modified this file to load the correct database before executing. Then run 
<div class="highlight"><span class="filename">bash</span><pre><span></span><code>python<span class="w"> </span>scripts/dup_detection.py
</code></pre></div></p>
</details>
<!-- The output for a database named `DB` is saved under `data/DB/dup_detection/dup_detection_candidates_DB.csv`.

<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">dup</span><span class="o">.</span><span class="n">find_duplicates_optimized</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">n_points_thresh</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="err">```</span> <span class="o">--&gt;</span>


<span class="c1">### 1.4 Optional: display the duplicate candidate summary figures</span>

<span class="o">&lt;</span><span class="err">!</span><span class="o">--</span> <span class="o">*</span><span class="n">OPTIONAL</span><span class="o">*</span><span class="p">:</span> <span class="n">plot</span> <span class="n">the</span> <span class="n">duplicate</span> <span class="n">candidate</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">which</span> <span class="n">were</span> <span class="n">flagged</span> <span class="n">by</span> <span class="n">the</span> <span class="n">duplicate</span> <span class="n">detection</span> <span class="n">algorithm</span><span class="o">.</span> 
<span class="n">The</span> <span class="n">function</span> <span class="err">`</span><span class="n">plot_duplicates</span><span class="err">`</span> <span class="n">loads</span> <span class="n">the</span> <span class="n">flagged</span> <span class="n">candidate</span> <span class="n">pairs</span> <span class="k">for</span> <span class="n">a</span> <span class="n">database</span> <span class="n">named</span> <span class="err">`</span><span class="n">DB</span><span class="err">`</span> <span class="kn">from</span><span class="w"> </span><span class="nn">csv</span> <span class="p">(</span><span class="err">`</span><span class="n">data</span><span class="o">/</span><span class="n">DB</span><span class="o">/</span><span class="n">dup_detection</span><span class="o">/</span><span class="n">dup_detection_candidates_DB</span><span class="o">.</span><span class="n">csv</span><span class="err">`</span><span class="p">)</span> <span class="ow">and</span> <span class="n">produces</span> <span class="n">summary</span> <span class="n">figures</span> <span class="n">of</span> <span class="n">the</span> <span class="n">potential</span> <span class="n">duplicates</span><span class="p">,</span> <span class="n">which</span> <span class="n">are</span> <span class="n">saved</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">directory</span> <span class="err">`</span><span class="n">figs</span><span class="o">/</span><span class="n">DB</span><span class="o">/</span><span class="n">dup_detection</span><span class="o">/</span><span class="err">`</span><span class="o">.</span>

<span class="o">**</span><span class="n">Note</span> <span class="n">that</span> <span class="n">the</span> <span class="n">same</span> <span class="n">summary</span> <span class="n">figures</span> <span class="n">are</span> <span class="n">being</span> <span class="n">used</span> <span class="k">for</span> <span class="n">the</span> <span class="n">duplicate</span> <span class="n">decision</span> <span class="n">process</span> <span class="p">(</span><span class="err">`</span><span class="n">dup_decisions</span><span class="o">.</span><span class="n">ipynb</span><span class="err">`</span><span class="p">)</span><span class="o">.**</span>

<span class="n">Run</span>
<span class="err">```</span><span class="n">python</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;python3/Jupyter&quot;</span>
<span class="n">dup</span><span class="o">.</span><span class="n">plot_duplicates</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">save_figures</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
 -->

<p><em>Optional:</em> Plot flagged candidate pairs. Figures are saved to <code>figs/DB/dup_detection/</code>.</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">dup</span><span class="o">.</span><span class="n">plot_duplicates</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">save_figures</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These same figures are used in the duplicate decision process.</p>
</div>
<h2 id="step-2-duplicate-decisions-dup_decisionipynb"><strong>Step 2: Duplicate decisions (<code>dup_decision.ipynb</code>)</strong></h2>
<p><strong>Notebook:</strong> <a href="../../notebooks/dup_decision/"><code>dup_decision.ipynb</code></a></p>
<p>This interactive notebook (<code>dup_decision.ipynb</code>) runs a duplicate decision algorithm for a specific database, following the identification of the potential duplicate candidate pairs. The algorithm walks the operator through each of the detected duplicate candidate pairs from <code>dup_detection.ipynb</code> and runs a decision process to decide whether to keep or reject the identified records.  </p>
<h3 id="21-initialisation">2.1 Initialisation</h3>
<p>To set up the working directory and load the compact dataframe, please follow the instructions detailed in  steps 1.1 (set up working directory) and 1.2 (load compact dataframe). </p>
<p>In addition, the operator is asked to provide their credentials along with the decision process. Please fill in your details:</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">initials</span> <span class="o">=</span> <span class="s1">&#39;FN&#39;</span>
<span class="n">fullname</span> <span class="o">=</span> <span class="s1">&#39;Full Name&#39;</span>
<span class="n">email</span>    <span class="o">=</span> <span class="s1">&#39;name@email.ac.uk&#39;</span>
<span class="n">operator_details</span> <span class="o">=</span> <span class="p">[</span><span class="n">initials</span><span class="p">,</span> <span class="n">fullname</span><span class="p">,</span> <span class="n">email</span><span class="p">]</span>
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">Why Credentials?</p>
<ul>
<li>Initials label intermediate output files</li>
<li>Name and email ensure transparency and traceability</li>
</ul>
</div>
<!-- The initials are used to label the intermediate output files for the next steps of the workflow, and the name and email address will be saved in the final duplicate free dataframe to ensure transparency and traceability. -->

<h3 id="22-hierarchy-for-duplicate-removal-for-identical-duplicates">2.2 Hierarchy for duplicate removal for identical duplicates</h3>
<p>For automated decisions, which apply to <em>identical</em> duplicates, we have defined a hierarchy of databases, which decides which record should be kept.</p>
<p>The hierarchy is assigned to the original databases, from 1 the highest value (should always be kept) to the lowest value n (the number of original databases). The hierarchy is added to the dataframe as an additional column (<code>Hierarchy</code>) for the decision process. Note that this parameter is not migrated to the final duplicate free database. </p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="c1"># implement hierarchy for automated decisions for identical records</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">dup</span><span class="o">.</span><span class="n">define_hierarchy</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">hierarchy</span><span class="o">=</span><span class="s1">&#39;default&#39;</span><span class="p">)</span>
</code></pre></div>
<p>The default hierarchy is given as</p>
<p>PAGES2k v2.2.0 &lt; FE23 (Breitenmoser et al. (2014)) &lt; CoralHydro2k v1.0.1 &lt; Iso2k v1.1.2 &lt; SISAL v3.</p>
<p>The hierarchy can be changed by providing a dictionary to the <code>hierarchy</code> kwarg:
<div class="highlight"><pre><span></span><code>hierarchy={&#39;pages2k&#39;: pages2k_value, &#39;fe23&#39;: fe23_value, &#39;iso2k&#39;: iso2k_value, &#39;ch2k&#39;: ch2k_value, &#39;sisal&#39;: sisal_value}
</code></pre></div></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hierarchy is not saved in the final duplicate-free database.</p>
</div>
<p>In order to reduce the operator workload, you also have the option to implement an automatic choice for specific database combinations. Please also specify a reason when doing so!</p>
<p>This is meant to be for any records which do not satisfy the hierarchy criterion, i.e. records with different data but identical metadata, such as updated records. </p>
<p>If you do not wish to do this, delete <code>automate_db_choice</code> from kwargs or set to <code>False</code> (default).</p>
<p>For example we have set </p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">automate_db_choice</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;preferred_db&#39;</span><span class="p">:</span> <span class="s1">&#39;FE23 (Breitenmoser et al. (2014))&#39;</span><span class="p">,</span> 
                      <span class="s1">&#39;rejected_db&#39;</span><span class="p">:</span> <span class="s1">&#39;PAGES 2k v2.2.0&#39;</span><span class="p">,</span> 
                      <span class="s1">&#39;reason&#39;</span><span class="p">:</span> <span class="s1">&#39;conservative replication requirement&#39;</span><span class="p">}</span>
</code></pre></div>
<h3 id="23-duplicate-decision-process">2.3 Duplicate decision process</h3>
<p>Run the decision algorithm:
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">dup</span><span class="o">.</span><span class="n">duplicate_decisions_multiple</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">operator_details</span><span class="o">=</span><span class="n">operator_details</span><span class="p">,</span> <span class="n">choose_recollection</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                 <span class="n">remove_identicals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">backup</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">comment</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">automate_db_choice</span><span class="o">=</span><span class="n">automate_db_choice</span><span class="p">)</span>
</code></pre></div>
<strong>Decision options for each pair:</strong></p>
<ul>
<li>keep both records</li>
<li>keep just one record</li>
<li>delete both records</li>
<li>create composite of both records.</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Automated Decisions</p>
<ul>
<li>Recollections/updates: automatically selected</li>
<li>Identical duplicates: highest hierarchy record kept automatically</li>
<li>Automate db choice: as described previously</li>
</ul>
</div>
<!-- Recollections and updates of duplicates are automatically selected (`choose_recollection=True`), as well as identical duplicates following the hierarchy defined above (`remove_identicals=True`).  -->

<!-- The duplicate decision algorithm is then initiated via:

<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">dup</span><span class="o">.</span><span class="n">duplicate_decisions</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">operator_details</span><span class="o">=</span><span class="n">operator_details</span><span class="p">,</span> <span class="n">choose_recollection</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                        <span class="n">remove_identicals</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
This function goes one-by-one through the individual duplicate candidate pairs and scans the data and metadata. For identical duplicates (defined as very high correlation and identical metadata, or perfect correlation), the algorithm makes an automated decision, in which the database with the highest hierarchical position is being chosen to keep (decision `KEEP`), while the other record will be removed (decision `REMOVE`). For other duplciates, the operator needs to provide manual input, based on a summary figure (see Figure 1).  -->

<!-- <figure markdown="span">
  ![Duplicate summary figure](../assets/images/dup_detection/duplicate_candidate_pair.jpg){ width="800" }
  <figcaption>Figure 1: Summary figure of a potential duplicate candidate pair, for which the operator is asked to make a decision.</figcaption>
</figure>

The operator is first presented with the option to leave a note on the decision process: 

<div class="highlight"><pre><span></span><code>**Decision required for this duplicate pair (see figure above).**
Before inputting your decision. Would you like to leave a comment on your decision process?
</code></pre></div>

This adds transparency on the decision process and justifies the operators choices. 

Next, the operator is asked to make the following decision, for example:

<div class="highlight"><pre><span></span><code>Keep record 1 (pages2k_50, black) [1], record 2 (FE23_northamerica_canada_cana091, blue) [2], keep both [b], keep none [n] or create a composite of both records [c]?  [Type 1/2/b/n/c]
</code></pre></div>

For candidate pairs which have a very high correlation and.or for which the metadata is identical, we have implemented an automated choice, in which the data record from the most recently published database is automatically chosen. This means less user inout is required and is especially helpful for very large databases with hundreds of duplicates. 


!!! Note

    The operator has the option to restart the decision process from a backup file in the directory `data/DB/dup_detection`. This can be especially useful should the connection be interrupted during the process. If such a file exists, the operator would be asked wether they want to use this file to restart the decision process. The decision process will then restart where the backup file cut out. This works for multiple interruptions.

??? question "Can I reverse a decision?"

    There is currently no option to reverse a decision while running the duplicate decisions. However should the operator want to revise a previous decision they have two options: 

    1. If this concerns the most recent decision, the operator should interrupt the decision process and remove the last line from the backup file (`data/DB/dup_detection/dup_decisions_DB_INITIALS_BACKUP.csv`). They could then restart the decision process and the process will restart from the last line in the backup file, so the operator has the opportunity to revise their last decision.

    2. They could interrupt the decision process and directly edit the backup file. The backup file (`data/DB/dup_detection/dup_decisions_DB_INITIALS_BACKUP.csv`) is a spreasheet which can be edited directly and the decisions can be revised under 'Decision 1' and 'Decision 2' (columns X and Y in Microsoft Excel). Note that the operator should keep to the standard terminology of input to avoid problems further downstream, i.e. use `KEEP`, `REMOVE` or `COMPOSITE` only. 

    3. The operator could complete the decision process and manually edit the final decision output file. Please make sure to use correct terminology as in option #2.


The final output is saved in `data/DB/dup_detection/dup_decisions_dod2k_dupfree_INITIALS_DATE.csv`

Summary figures are saved in the directory `figs/dup_detection/DB`, and are also linked in the output csv file. -->

<p><strong>Example prompts:</strong></p>
<figure>
  <img alt="Duplicate summary figure" src="../../assets/images/dup_detection/duplicate_summary.png" width="800" />
<br />
<figcaption>Figure 1: Summary figure of a potential duplicate candidate pair, for which the operator is asked to make a decision.</figcaption>
</figure>
<p><div class="highlight"><pre><span></span><code>**Decision required for this duplicate pair (see figure above).**
Before inputting your decision.
Would you like to leave a comment on your decision process?
**COMMENT** Please type your comment here and/or press enter.
</code></pre></div>
<div class="highlight"><pre><span></span><code> **DECISION** Keep record 1 (pages2k_50, blue circles) [1],
record 2 (FE23_northamerica_canada_cana091, red crosses) [2],
keep both [b], keep none [n] or create a composite of both records [c]?
Note: only overlapping timesteps are being composited. [Type 1/2/b/n/c]:
</code></pre></div></p>
<p><strong>Output:</strong> <code>data/DB/dup_detection/dup_decisions_dod2k_dupfree_INITIALS_DATE.csv</code></p>
<p><strong>Figures:</strong> <code>figs/dup_detection/DB/</code> (linked in output CSV)</p>
<div class="admonition note">
<p class="admonition-title">Backup &amp; Resume</p>
<p>The process creates backup files in <code>data/DB/dup_detection/</code>. If interrupted, you can resume from the backup.</p>
</div>
<details class="question">
<summary>Can I Reverse a Decision?</summary>
<p>There is currently no option to reverse a decision while running the duplicate decisions. 
However should the operator want to revise a previous decision they have two options: </p>
<ol>
<li>
<p><strong>Most recent decision:</strong> Interrupt the process, remove the last line from the backup file (<code>data/DB/dup_detection/dup_decisions_DB_INITIALS_BACKUP.csv</code>), then restart.</p>
</li>
<li>
<p><strong>Any decision:</strong> Interrupt and directly edit the backup file columns 'Decision 1' and 'Decision 2'. Use only: <code>KEEP</code>, <code>REMOVE</code>, or <code>COMPOSITE</code>.</p>
</li>
<li>
<p><strong>After completion:</strong> Manually edit the final output file with correct terminology.</p>
</li>
</ol>
</details>
<div class="admonition info">
<p class="admonition-title">Handling of multiple duplicates</p>
<p>The decision process is currently not optimised for handling of multiple duplicates (i.e. records which have more than one potential duplicate candidate), going through the duplicates on a pair-by-pair basis. However, <code>dup.duplicate_decisions_multiple</code> includes improved handling of multiple duplicates. For any records which are associated with multiple duplicates, all the other duplicate candidates are shown alongside the summary figure for the duplicate candidate pair. Any previous decisions, when available, are shown besides the <code>datasetId</code>, <code>archiveType</code>, <code>paleoData_proxy</code> etc.:</p>
<div class="highlight"><pre><span></span><code>***ATTENTION*** THIS RECORD IS ASSOCIATED WITH MULTIPLE DUPLICATES! 
PLEASE PAY SPECIAL ATTENTION WHEN MAKING DECISIONS FOR THIS RECORD!
The potential duplicates also associated with this record are:
 Dataset ID          : iso2k_786
     - URL                 : https://www.ncdc.noaa.gov/paleo/study/1856
</code></pre></div>
<p><figure markdown="span">
  <img alt="Multiple summary figure" src="../../assets/images/dup_detection/duplicate_multiples.png" width="800" />
  <figcaption>Figure 2: Summary figure for multiple duplicates.</figcaption>
</figure></p>
<p>The operator can then make an informed decision for each candidate pair.</p>
</div>
<hr />
<h2 id="step-3-duplicate-removal-dup_removalipynb"><strong>Step 3: Duplicate removal (<code>dup_removal.ipynb</code>)</strong></h2>
<p><strong>Notebook:</strong> <a href="../../notebooks/dup_removal/"><code>dup_removal.ipynb</code></a></p>
<p>This notebook removes duplicates based on decisions from Step 2.</p>
<!-- This interactive notebook (`dup_removal.ipynb`) removes the duplicates flagged in `dup_detection.ipynb`, following the decisions made in `dup_decision.ipynb`. The decisions include
- removal of redundant duplicates
- creation of composites

 To view the interactive notebook see [dup_removal.ipynb](../notebooks/dup_removal.ipynb).  -->

<h3 id="31-initialisation">3.1 Initialisation</h3>
<p>To set up the working directory and load the compact dataframe, please follow the instructions detailed in steps 1.1 (set up working directory), 1.2 (load compact dataframe) and 2.1 (provide operator credentials).</p>
<p>In addition, <code>datasetId</code> needs to be set as dataframe index to reliably identify the duplicates later on:
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;datasetId&#39;</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;datasetId&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">index</span>
</code></pre></div></p>
<h3 id="32-load-duplicate-decisions-from-csv">3.2 Load duplicate decisions from csv</h3>
<p>In order to load the duplicate decisions from csv, the operator <em>initials</em> and the <em>date</em> need to be specified, to match the desired decision output file.</p>
<p>Accordingly, the decision output file is loaded from <code>data/DBNAME/dup_detection/dup_decisions_DBNAME_INITIALS_DATE.csv</code>:</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">filename</span>      <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;data/</span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">/dup_detection/dup_decisions_</span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">initials</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="n">data</span><span class="p">,</span> <span class="n">header</span>  <span class="o">=</span> <span class="n">dup</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_decisions</span>  <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="o">+</span><span class="s1">&#39;.csv&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>
<p><code>dup.read_csv</code> provides the <code>header</code>, which details the operator's details as provided in the decision file, along with any comments on the general decision process. Later in the notebook, <code>header</code> is written into a metadata file which should be provided alongside the duplicate free dataset. <code>df_decisions</code> is a <code>pandas</code> dataframe which is populated with the decision data, record by record, and will be used to implement the decisions to create a duplicate free dataset.</p>
<h3 id="33-implement-duplicate-decisions">3.3 Implement duplicate decisions</h3>
<p>From <code>df_decisions</code> we extract a dictionary which includes all decisions for each individual record:</p>
<p><div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">decisions</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">id1</span><span class="p">,</span> <span class="n">id2</span>   <span class="o">=</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;datasetId 1&#39;</span><span class="p">,</span> <span class="s1">&#39;datasetId 2&#39;</span><span class="p">]]</span>
    <span class="n">dec1</span><span class="p">,</span> <span class="n">dec2</span> <span class="o">=</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Decision 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision 2&#39;</span><span class="p">]]</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">dec</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">id1</span><span class="p">,</span> <span class="n">id2</span><span class="p">],</span> <span class="p">[</span><span class="n">dec1</span><span class="p">,</span> <span class="n">dec2</span><span class="p">]):</span>
        <span class="k">if</span> <span class="nb">id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">decisions</span><span class="p">:</span> <span class="n">decisions</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">decisions</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="o">+=</span><span class="p">[</span><span class="n">dec</span><span class="p">]</span>
</code></pre></div>
This dictionary can be used to identify and track multiple decisions, as well as to review the choices made.</p>
<p>We also extract details of each decisions, which will later be used to populate the field <code>duplicateDetails</code> in the final dataframe (the output of this notebook):</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">dup_details</span> <span class="o">=</span> <span class="n">dup</span><span class="o">.</span><span class="n">provide_dup_details</span><span class="p">(</span><span class="n">df_decisions</span><span class="p">,</span> <span class="n">header</span><span class="p">)</span>
</code></pre></div>
<p>&lt;!-- carries the information on all the duplicate decisions. For each duplicate pair, the dictionary is populated with information about the respective duplicate and the duplicate decision process. Note that we also account for multiple duplicates. This dictionary is used to populate the column <code>duplicateDetails</code> in the finalised duplicate free dataframe (<code>df_dupfree</code>).</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">dup_details</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">dup_counts</span>  <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">dec_1</span><span class="p">,</span> <span class="n">dec_2</span> <span class="o">=</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Decision 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision 2&#39;</span><span class="p">]]</span>
    <span class="k">if</span> <span class="n">dec_1</span><span class="o">==</span><span class="s1">&#39;KEEP&#39;</span> <span class="ow">and</span> <span class="n">dec_2</span><span class="o">==</span><span class="s1">&#39;KEEP&#39;</span><span class="p">:</span> <span class="k">continue</span> <span class="c1"># in this case no true duplicates!</span>

    <span class="n">id_1</span><span class="p">,</span> <span class="n">id_2</span> <span class="o">=</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;datasetId 1&#39;</span><span class="p">,</span> <span class="s1">&#39;datasetId 2&#39;</span><span class="p">]]</span>
    <span class="n">db_1</span><span class="p">,</span> <span class="n">db_2</span> <span class="o">=</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;originalDatabase 1&#39;</span><span class="p">,</span> <span class="s1">&#39;originalDatabase 2&#39;</span><span class="p">]]</span>
    <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="p">[</span><span class="n">id_1</span><span class="p">,</span> <span class="n">id_2</span><span class="p">]:</span>
        <span class="k">if</span> <span class="nb">id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dup_details</span><span class="p">:</span>
            <span class="n">dup_counts</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">dup_details</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dup_counts</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="o">+=</span><span class="mi">1</span>
    <span class="n">dup_details</span><span class="p">[</span><span class="n">id_1</span><span class="p">][</span><span class="n">dup_counts</span><span class="p">[</span><span class="n">id_1</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;duplicate ID&#39;</span><span class="p">:</span> <span class="n">id_2</span><span class="p">,</span> <span class="s1">&#39;duplicate database&#39;</span><span class="p">:</span> <span class="n">db_2</span><span class="p">,</span> <span class="s1">&#39;duplicate decision&#39;</span><span class="p">:</span> <span class="n">dec_2</span><span class="p">,</span> <span class="s1">&#39;decision type&#39;</span><span class="p">:</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="s1">&#39;Decision type&#39;</span><span class="p">]}</span>
    <span class="n">dup_details</span><span class="p">[</span><span class="n">id_2</span><span class="p">][</span><span class="n">dup_counts</span><span class="p">[</span><span class="n">id_2</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;duplicate ID&#39;</span><span class="p">:</span> <span class="n">id_1</span><span class="p">,</span> <span class="s1">&#39;duplicate database&#39;</span><span class="p">:</span> <span class="n">db_1</span><span class="p">,</span> <span class="s1">&#39;duplicate decision&#39;</span><span class="p">:</span> <span class="n">dec_1</span><span class="p">,</span> <span class="s1">&#39;decision type&#39;</span><span class="p">:</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="s1">&#39;Decision type&#39;</span><span class="p">]}</span>

    <span class="k">if</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="s1">&#39;Decision type&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;MANUAL&#39;</span><span class="p">:</span> 
        <span class="n">operator_details</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">header</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; Modified &#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;  E-Mail&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="p">[</span><span class="n">id_1</span><span class="p">,</span> <span class="n">id_2</span><span class="p">]:</span>
            <span class="n">dup_details</span><span class="p">[</span><span class="nb">id</span><span class="p">][</span><span class="n">dup_counts</span><span class="p">[</span><span class="nb">id</span><span class="p">]][</span><span class="s1">&#39;operator&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">operator_details</span>
            <span class="n">dup_details</span><span class="p">[</span><span class="nb">id</span><span class="p">][</span><span class="n">dup_counts</span><span class="p">[</span><span class="nb">id</span><span class="p">]][</span><span class="s1">&#39;note&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_decisions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="s1">&#39;Decision comment&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="p">[</span><span class="n">id_1</span><span class="p">,</span> <span class="n">id_2</span><span class="p">]:</span>
            <span class="n">dup_details</span><span class="p">[</span><span class="nb">id</span><span class="p">][</span><span class="n">dup_counts</span><span class="p">[</span><span class="nb">id</span><span class="p">]][</span><span class="s1">&#39;operator&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;N/A&#39;</span>
            <span class="n">dup_details</span><span class="p">[</span><span class="nb">id</span><span class="p">][</span><span class="n">dup_counts</span><span class="p">[</span><span class="nb">id</span><span class="p">]][</span><span class="s1">&#39;note&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;N/A&#39;</span>       
<span class="err">```</span> <span class="o">--&gt;</span>

<span class="err">!!!</span> <span class="n">Note</span>

    <span class="n">Note</span> <span class="n">that</span> <span class="nb">any</span> <span class="n">one</span> <span class="n">record</span> <span class="n">can</span> <span class="n">appear</span> <span class="n">more</span> <span class="n">than</span> <span class="n">once</span> <span class="ow">and</span> <span class="n">have</span> <span class="n">multiple</span> <span class="n">decisions</span> <span class="n">associated</span> <span class="k">with</span> <span class="n">it</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span> <span class="err">`</span><span class="s1">&#39;REMOVE&#39;</span><span class="err">`</span><span class="p">,</span> <span class="err">`</span><span class="s1">&#39;KEEP&#39;</span><span class="err">`</span> <span class="ow">or</span> <span class="err">`</span><span class="s1">&#39;COMPOSITE&#39;</span><span class="err">`</span><span class="p">)</span><span class="o">.</span>

    <span class="n">In</span> <span class="n">order</span> <span class="n">to</span> <span class="n">remove</span> <span class="n">the</span> <span class="n">duplicates</span> <span class="n">we</span> <span class="n">therefore</span> <span class="n">implement</span> <span class="n">the</span> <span class="n">following</span> <span class="n">steps</span><span class="p">:</span>

    <span class="mf">1.</span> <span class="o">**</span><span class="n">Remove</span><span class="o">**</span> <span class="nb">all</span> <span class="n">records</span> <span class="kn">from</span><span class="w"> </span><span class="nn">the</span> <span class="n">dataframe</span> <span class="n">which</span> <span class="n">are</span> <span class="n">associated</span> <span class="k">with</span> <span class="n">the</span> <span class="n">decision</span> <span class="err">`</span><span class="s1">&#39;REMOVE&#39;</span><span class="err">`</span> <span class="ow">or</span> <span class="err">`</span><span class="n">COMPOSITE</span><span class="err">`</span> <span class="o">-&gt;</span> <span class="err">`</span><span class="n">df_cleaned</span><span class="err">`</span>
    <span class="mf">2.</span> <span class="o">**</span><span class="n">Create</span> <span class="n">composites</span><span class="o">**</span> <span class="n">of</span> <span class="n">the</span> <span class="err">`</span><span class="n">COMPOSITE</span><span class="err">`</span> <span class="n">records</span> <span class="o">-&gt;</span> <span class="err">`</span><span class="n">df_composite</span><span class="err">`</span>
    <span class="mf">3.</span> <span class="o">**</span><span class="n">Check</span><span class="o">**</span> <span class="k">for</span> <span class="n">records</span> <span class="n">which</span> <span class="n">have</span> <span class="n">multiple</span> <span class="n">decisions</span> <span class="n">associated</span><span class="o">.</span> <span class="n">These</span> <span class="n">are</span> <span class="n">potentially</span> <span class="n">remaining</span> <span class="n">duplicates</span><span class="o">.</span>

<span class="c1">#### 3.3.1. Records to be removed</span>
<span class="n">First</span> <span class="n">simply</span> <span class="n">remove</span> <span class="nb">all</span> <span class="n">the</span> <span class="n">records</span> <span class="n">to</span> <span class="n">which</span> <span class="n">the</span> <span class="n">decision</span> <span class="err">`</span><span class="n">REMOVE</span><span class="err">`</span> <span class="ow">or</span> <span class="err">`</span><span class="n">COMPOSITE</span><span class="err">`</span> <span class="n">applies</span> <span class="n">to</span> <span class="ow">and</span> <span class="n">store</span> <span class="ow">in</span> <span class="err">`</span><span class="n">df_cleaned</span><span class="err">`</span><span class="p">,</span> <span class="k">while</span> <span class="nb">all</span> <span class="err">`</span><span class="s1">&#39;REMOVE&#39;</span><span class="err">`</span> <span class="ow">or</span> <span class="err">`</span><span class="s1">&#39;COMPOSITE&#39;</span><span class="err">`</span> <span class="nb">type</span> <span class="n">records</span> <span class="n">are</span> <span class="n">stored</span> <span class="ow">in</span> <span class="err">`</span><span class="n">df_duplica_rmv</span><span class="err">`</span> <span class="p">(</span><span class="k">for</span> <span class="n">later</span> <span class="n">inspection</span><span class="p">)</span><span class="o">.</span>

<span class="err">```</span><span class="n">python</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;python3/Jupyter&#39;</span>
<span class="c1"># load the records TO BE REMOVED</span>
<span class="n">remove_IDs</span>  <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df_decisions</span><span class="p">[</span><span class="s1">&#39;datasetId 1&#39;</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">df_decisions</span><span class="p">[</span><span class="s1">&#39;Decision 1&#39;</span><span class="p">],[</span><span class="s1">&#39;REMOVE&#39;</span><span class="p">,</span> <span class="s1">&#39;COMPOSITE&#39;</span><span class="p">])])</span>
<span class="n">remove_IDs</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df_decisions</span><span class="p">[</span><span class="s1">&#39;datasetId 2&#39;</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">df_decisions</span><span class="p">[</span><span class="s1">&#39;Decision 2&#39;</span><span class="p">],[</span><span class="s1">&#39;REMOVE&#39;</span><span class="p">,</span> <span class="s1">&#39;COMPOSITE&#39;</span><span class="p">])])</span>
<span class="n">remove_IDs</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">remove_IDs</span><span class="p">)</span>

<span class="n">df_duplica</span>     <span class="o">=</span>  <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">remove_IDs</span><span class="p">,</span> <span class="s1">&#39;datasetId&#39;</span><span class="p">]</span> <span class="c1"># df containing only records which were removed</span>
<span class="n">df_cleaned</span> <span class="o">=</span>  <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">remove_IDs</span><span class="p">)</span> <span class="c1"># df freed from &#39;REMOVE&#39; type duplicates</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Removed </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_duplica</span><span class="p">)</span><span class="si">}</span><span class="s1"> REMOVE or COMPOSITE type records.&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;REMOVE type duplicate free dataset contains </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">)</span><span class="si">}</span><span class="s1"> records.&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Removed the following IDs:&#39;</span><span class="p">,</span> <span class="n">remove_IDs</span><span class="p">)</span>
</code></pre></div>
<p><code>df_cleaned</code> then contains all data apart from records which are marked as <code>REMOVE</code> or <code>COMPOSITE</code>. Thus, it only keeps the records which either were never marked as duplicates or where the operator had decided to keep a duplicate. </p>
<p>Note that the <code>duplicateDetails</code> need to be added to <code>df_cleaned</code> via</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">df_cleaned</span><span class="p">[</span><span class="s1">&#39;duplicateDetails&#39;</span><span class="p">]</span><span class="o">=</span><span class="s1">&#39;N/A&#39;</span>
<span class="k">for</span> <span class="n">ID</span> <span class="ow">in</span> <span class="n">dup_details</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">ID</span> <span class="ow">in</span> <span class="n">df_cleaned</span><span class="o">.</span><span class="n">index</span><span class="p">:</span> 
        <span class="k">if</span> <span class="n">df_cleaned</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">ID</span><span class="p">,</span> <span class="s1">&#39;duplicateDetails&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;N/A&#39;</span><span class="p">:</span> 
            <span class="n">df_cleaned</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">ID</span><span class="p">,</span> <span class="s1">&#39;duplicateDetails&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">dup_details</span><span class="p">[</span><span class="n">ID</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">df_cleaned</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">ID</span><span class="p">,</span> <span class="s1">&#39;duplicateDetails&#39;</span><span class="p">]</span><span class="o">+=</span><span class="n">dup_details</span><span class="p">[</span><span class="n">ID</span><span class="p">]</span>
</code></pre></div>
<h4 id="332-records-to-be-composited">3.3.2. Records to be composited</h4>
<p>Now identify all the records to which the decision <code>'COMPOSITE'</code> applies to, create composites and store in <code>df_composite</code>. 
For differences in the numerical metadata we use the average (e.g. <code>geo_meanLat</code>, <code>geo_meanLon</code>, ...), while for string types we merge the strings to form a composite. The <code>datasetId</code> is created from both original values to <code>'f{df.name}_composite_z_{ID_1}_{ID_2}'</code>, with <code>ID_1</code> and <code>ID_2</code> the original <code>datasetId</code> for each record. The data is being composited by averaging the z-scores of the original data. </p>
<p><div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="c1"># add the column &#39;duplicateDetails&#39; to df, in case it does not exist</span>
<span class="k">if</span> <span class="s1">&#39;duplicateDetails&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;duplicateDetails&#39;</span><span class="p">]</span><span class="o">=</span><span class="s1">&#39;N/A&#39;</span>

<span class="c1"># load the records to be composited</span>
<span class="n">comp_ID_pairs</span> <span class="o">=</span> <span class="n">df_decisions</span><span class="p">[(</span><span class="n">df_decisions</span><span class="p">[</span><span class="s1">&#39;Decision 1&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;COMPOSITE&#39;</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">df_decisions</span><span class="p">[</span><span class="s1">&#39;Decision 2&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;COMPOSITE&#39;</span><span class="p">)]</span>

<span class="c1"># create new composite data and metadata from the pairs</span>
<span class="c1"># loop through the composite pairs and check metadata</span>
<span class="n">df_composite</span> <span class="o">=</span> <span class="n">dup</span><span class="o">.</span><span class="n">join_composites_metadata</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">comp_ID_pairs</span><span class="p">,</span> <span class="n">df_decisions</span><span class="p">,</span> <span class="n">header</span><span class="p">)</span>
</code></pre></div>
The function <code>join_composites_metadata</code> also creates summary figures of the composites in order to supervise the composition process. </p>
<h4 id="333-check-for-multiple-duplicate-records-with-different-decisions">3.3.3. Check for multiple duplicate records with different decisions</h4>
<p>In order to obtain the duplicate free dataframe we merge <code>df_cleaned</code> and <code>df_composite</code>:</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">tmp_df_dupfree</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_cleaned</span><span class="p">,</span> <span class="n">df_composite</span><span class="p">])</span>
<span class="n">tmp_df_dupfree</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">tmp_df_dupfree</span><span class="p">[</span><span class="s1">&#39;datasetId&#39;</span><span class="p">]</span>
<span class="n">tmp_decisions</span> <span class="o">=</span> <span class="n">decisions</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</code></pre></div>
<p>This dataframe initiates a loop in which the records which are associated with multiple decisions are fed into another round of duplicate detection, decisions and removal. This is necessary to ensure that no duplicates remain in the merged dataframe because of combined decisions such as for example:</p>
<ul>
<li><code>REMOVE</code>/<code>KEEP</code> and <code>COMPOSITE</code>:</li>
<li>duplicate pair <code>a</code> and <code>b</code> have had the decisions assigned: <code>a</code>-&gt; <code>REMOVE</code>, <code>b</code> -&gt; <code>KEEP</code></li>
<li>duplicate pair <code>a</code> and <code>c</code> have had the decisions assigned: <code>a</code> -&gt; <code>COMPOSITE</code>, <code>c</code> -&gt; <code>COMPOSITE</code>.</li>
</ul>
<p>In this case, <code>b</code> and <code>ac</code> (the composite record of <code>a</code> and <code>c</code>) would be <span style="color:red"><strong>duplicates in the merged dataframe</strong></span></p>
<ul>
<li>
<p><code>REMOVE</code>/<code>KEEP</code> &amp; <code>REMOVE</code>/<code>KEEP</code></p>
</li>
<li>
<p>duplicate pair <code>a</code> and <code>b</code> have had the decisions assigned: <code>a</code>-&gt; <code>REMOVE</code>, <code>b</code> -&gt; <code>KEEP</code></p>
</li>
<li>
<p>duplicate pair <code>a</code> and <code>c</code> have had the decisions assigned: <code>a</code> -&gt; <code>REMOVE</code>, <code>c</code> -&gt; <code>KEEP</code>.</p>
<p>In this case, <code>a</code> would be removed, but <code>b</code> and <code>c</code> will be kept and would be <span style="color:red"><strong>duplicates in the merged dataframe</strong></span>. </p>
</li>
<li>
<p><code>COMPOSITE</code> x 2</p>
</li>
<li>duplicate pair <code>a</code> and <code>b</code> have had the decisions assigned: <code>a</code>-&gt; <code>COMPOSITE</code>, <code>b</code> -&gt; <code>COMPOSITE</code></li>
<li>duplicate pair <code>a</code> and <code>c</code> have had the decisions assigned: <code>a</code> -&gt; <code>COMPOSITE</code>, <code>c</code> -&gt; <code>COMPOSITE</code>.</li>
</ul>
<p>In this case, <code>ab</code> and <code>ac</code> would be <span style="color:red"><strong>duplicates in the merged dataframe</strong></span>.</p>
<p>XXXX</p>
<p>Before merging and saving the duplicate free dataframe we still need to ensure that there is no overlap between <code>'COMPOSITE'</code> and <code>'REMOVE'</code> type duplicates. We first collect a list of these duplicates via </p>
<p><div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">overlap_rmv_cmp</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">decisions</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;REMOVE&#39;</span> <span class="ow">in</span> <span class="n">decisions</span><span class="p">[</span><span class="nb">id</span><span class="p">])</span><span class="o">&amp;</span><span class="p">(</span><span class="s1">&#39;COMPOSITE&#39;</span> <span class="ow">in</span> <span class="n">decisions</span><span class="p">[</span><span class="nb">id</span><span class="p">]):</span>
        <span class="n">overlap_rmv_cmp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">id</span><span class="p">)</span>
</code></pre></div>
If the list is empty, we can proceed to the merging and saving of <code>df_dupfree</code>. If not we need to address the overlap via </p>
<div class="admonition warning">
<p class="admonition-title">Coming Soon</p>
<p>Handling for overlaps is under development.</p>
</div>
<h3 id="34-save-duplicate-free-dataframe">3.4 Save duplicate free dataframe</h3>
<p>Merge <code>df_composite</code> and <code>df_cleaned</code> to create duplicate free dataframe:</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">df_dupfree</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_cleaned</span><span class="p">,</span> <span class="n">df_composite</span><span class="p">])</span>
</code></pre></div>
<p>Sort the columns and assign a name to the dataframe which is used for saving purposes (determines directory and filename). Make sure that <code>date</code> and operator initials <code>initials</code> are used in the name.</p>
<p><div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="n">df_dupfree</span> <span class="o">=</span> <span class="n">df_dupfree</span><span class="p">[</span><span class="nb">sorted</span><span class="p">(</span><span class="n">df_dupfree</span><span class="o">.</span><span class="n">columns</span><span class="p">)]</span>
<span class="n">df_dupfree</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">initials</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="s1">_dupfree&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;data/</span><span class="si">{</span><span class="n">df_dupfree</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">/&#39;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
Now save the dataframe to pickle, and to csv:</p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="c1"># save concatenate dataframe as db_merged</span>
<span class="n">df_dupfree</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;data/</span><span class="si">{</span><span class="n">df_dupfree</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">df_dupfree</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">_compact.pkl&#39;</span><span class="p">)</span>

<span class="c1"># save to a list of csv files (metadata, data, year)</span>
<span class="n">utf</span><span class="o">.</span><span class="n">write_compact_dataframe_to_csv</span><span class="p">(</span><span class="n">df_dupfree</span><span class="p">)</span>
</code></pre></div>
<p>We also need to preserve some metadata on the decision process via </p>
<div class="highlight"><span class="filename">python3/Jupyter</span><pre><span></span><code><span class="c1"># write header with operator information as README txt file</span>
<span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;data/</span><span class="si">{</span><span class="n">df_dupfree</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">df_dupfree</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">_dupfree_README.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">header</span><span class="p">:</span>
    <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="o">+</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Workflow Complete</p>
<p>The duplicate detection workflow is now finished!</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>For more details on the interactive notebooks, see 
1. <a href="../../notebooks/dup_detection/">dup_detection.ipynb</a>
2. <a href="../../notebooks/dup_decision/">dup_decision.ipynb</a>
3. <a href="../../notebooks/dup_removal/">dup_removal.ipynb</a></p>
</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>